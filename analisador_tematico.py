import pandas as pd
from pypdf import PdfReader
import re
import os
from datetime import datetime
from collections import Counter
import nltk
from nltk.corpus import stopwords

# Tenta baixar a lista de stopwords se ainda n√£o foi baixada
try:
    STOPWORDS_PT = set(stopwords.words('portuguese'))
except LookupError:
    print("Baixando 'stopwords' do NLTK...")
    nltk.download('stopwords')
    STOPWORDS_PT = set(stopwords.words('portuguese'))

# --- FUN√á√ïES DE EXTRA√á√ÉO ---

def extrair_texto_de_pdf(caminho_arquivo):
    """
    L√™ o PDF no caminho especificado e retorna todo o seu conte√∫do como texto.
    """
    texto_completo = ""
    try:
        reader = PdfReader(caminho_arquivo)
        for page in reader.pages:
            texto_completo += page.extract_text() + "\n"
        return texto_completo
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"‚ùå Ocorreu um erro durante a leitura do PDF: {e}")
        return None

# --- FUN√á√ÉO PRINCIPAL: AN√ÅLISE DE FREQU√äNCIA ---

def analisar_frequencia_tematica(texto, palavras_a_excluir=None, min_tamanho_palavra=3, top_n=50):
    """
    Processa o texto, remove stopwords e pontua√ß√£o, e conta a frequ√™ncia
    das palavras restantes (os temas e keywords).
    """
    if not texto:
        return pd.DataFrame(), 0

    # 1. Pr√©-processamento e Tokeniza√ß√£o
    # Remove pontua√ß√£o e caracteres especiais, exceto espa√ßos e h√≠fens internos
    # Inclui acentua√ß√£o em min√∫sculas
    texto_limpo = re.sub(r'[^a-z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ√ß\s-]', '', texto.lower())

    # Divide o texto em tokens (palavras)
    tokens = texto_limpo.split()

    # Combina a lista padr√£o de stopwords com quaisquer palavras extras
    palavras_excluidas = STOPWORDS_PT.union(set(palavras_a_excluir or []))

    # 2. Filtragem de Palavras Relevantes
    palavras_relevantes = [
        palavra
        for palavra in tokens
        if palavra not in palavras_excluidas and len(palavra) >= min_tamanho_palavra
    ]

    total_palavras_analisadas = len(palavras_relevantes)

    # 3. Contagem de Frequ√™ncia
    contagens = Counter(palavras_relevantes)

    # 4. Prepara√ß√£o do DataFrame
    df = pd.DataFrame(contagens.most_common(top_n), columns=['Palavra-Chave', 'Frequ√™ncia'])

    # C√°lculo da Frequ√™ncia Percentual
    if total_palavras_analisadas > 0:
        df['Frequ√™ncia (%)'] = (df['Frequ√™ncia'] / total_palavras_analisadas * 100).round(2)
    else:
        df['Frequ√™ncia (%)'] = 0.0

    return df, len(tokens) # Retorna o DataFrame das TOP N e o total de palavras do texto original

# --- 3. FUN√á√ÉO GERAR RELAT√ìRIO (CORRIGIDA) ---

def gerar_relatorio_tematico(caminho_arquivo, df_frequencia, total_palavras_brutas, top_n, min_tamanho_palavra):
    """
    Gera uma string de relat√≥rio formatada e a salva em um arquivo de texto.

    A corre√ß√£o incluiu 'min_tamanho_palavra' como par√¢metro.
    """
    nome_saida = "relatorio_frequencia_tematica.txt"

    relatorio = "=========================================================\n"
    relatorio += "| RELAT√ìRIO DE AN√ÅLISE DE FREQU√äNCIA TEM√ÅTICA |\n"
    relatorio += "=========================================================\n"
    relatorio += f"Data da An√°lise: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    relatorio += f"Arquivo Fonte: {caminho_arquivo}\n"
    relatorio += f"Total de Palavras Brutas no Texto: {total_palavras_brutas}\n"
    # CORRIGIDO: Agora min_tamanho_palavra est√° acess√≠vel como par√¢metro
    relatorio += f"Palavras Comuns (Stopwords) e Curta (m√≠n={min_tamanho_palavra}) Exclu√≠das.\n"
    relatorio += f"\n--- TOP {top_n} PALAVRAS-CHAVE MAIS FREQUENTES ---\n\n"

    if df_frequencia.empty:
        relatorio += "N√£o foi poss√≠vel calcular a frequ√™ncia de palavras-chave. Texto muito curto ou vazio.\n"
    else:
        # Adiciona a tabela de resultados
        relatorio += df_frequencia.to_string(index=False)
        relatorio += "\n\n"
        relatorio += "INTERPRETA√á√ÉO:\n"
        relatorio += "A coluna 'Palavra-Chave' indica os principais focos tem√°ticos do seu texto.\n"
        relatorio += "Alta 'Frequ√™ncia (%)' sugere que o tema √© central e recorrente.\n"

    # Salvar o relat√≥rio em arquivo
    try:
        with open(nome_saida, 'w', encoding='utf-8') as f:
            f.write(relatorio)
        return relatorio, nome_saida
    except Exception as e:
        return f"Erro ao escrever arquivo: {e}", None

# --- Bloco Principal de Execu√ß√£o (CORRIGIDO) ---
if __name__ == "__main__":

    # üìå CONFIGURA√á√ïES
    caminho_do_arquivo = 'main.pdf'
    top_n_palavras = 50

    # Vari√°vel de configura√ß√£o formalizada para ser passada √†s fun√ß√µes
    MIN_TAMANHO_PALAVRA = 3

    # Adicione aqui nomes de personagens espec√≠ficos ou palavras muito comuns que voc√™ quer ignorar
    palavras_extras_excluir = {'elizeu', 'montanha', 'castelo'}

    print(f"--- üìä Analisador de Frequ√™ncia Tem√°tica ---")

    if not os.path.exists(caminho_do_arquivo):
        print(f"‚ùå Erro: Arquivo '{caminho_do_arquivo}' n√£o encontrado. Usando texto de demonstra√ß√£o.")
        # Texto de demonstra√ß√£o
        texto_para_analisar = """
        O **drag√£o** voou sobre o **castelo** de Elizeu. O **tesouro** era o objetivo.
        Muitos drag√µes haviam falhado antes. O **tesouro** estava bem guardado.
        Elizeu defendia o **castelo** e seu **tesouro**. O **drag√£o** era enorme.
        A batalha pelo **tesouro** e o **castelo** come√ßou.
        O **drag√£o** atacou. (Repetir esta estrutura para gerar dados)
        """ * 15
        caminho_do_arquivo = "[DEMONSTRA√á√ÉO]"
    else:
        print(f"‚è≥ Extraindo texto do PDF: {caminho_do_arquivo}...")
        texto_para_analisar = extrair_texto_de_pdf(caminho_do_arquivo)


    if texto_para_analisar:

        # PASSO 1: AN√ÅLISE DE FREQU√äNCIA
        df_frequencia, total_palavras_brutas = analisar_frequencia_tematica(
            texto_para_analisar,
            palavras_a_excluir=palavras_extras_excluir,
            min_tamanho_palavra=MIN_TAMANHO_PALAVRA, # Passa o par√¢metro para 'analisar_frequencia_tematica'
            top_n=top_n_palavras
        )

        print(f"‚úÖ An√°lise conclu√≠da. Total de palavras brutas: {total_palavras_brutas}")

        # PASSO 2: GERAR E SALVAR RELAT√ìRIO
        # CHAMADA CORRIGIDA: Inclui o novo argumento
        relatorio_saida, nome_saida = gerar_relatorio_tematico(
            caminho_do_arquivo,
            df_frequencia,
            total_palavras_brutas,
            top_n_palavras,
            MIN_TAMANHO_PALAVRA # NOVO ARGUMENTO: Resolve o NameError
        )

        # IMPRIMIR O RELAT√ìRIO NO CONSOLE E INFORMAR O ARQUIVO
        print("\n" + relatorio_saida)

        if nome_saida:
            print("\n" + "="*70)
            print(f"SUCESSO! Relat√≥rio Tem√°tico salvo em: **{nome_saida}**")
            print("==========================================================")
    else:
        print("‚ö†Ô∏è O texto extra√≠do est√° vazio ou a extra√ß√£o falhou.")